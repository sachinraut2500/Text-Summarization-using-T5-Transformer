# -*- coding: utf-8 -*-
"""Text Summarization using T5 Transformer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pKYgrwW1BbCxeOcU-7lO2w31ebT7-_yO
"""

# text_summarization_t5.py

from transformers import T5Tokenizer, T5ForConditionalGeneration
import torch

def summarize(text, model, tokenizer, max_length=150, num_beams=4):
    inputs = tokenizer.encode("summarize: " + text, return_tensors="pt", max_length=512, truncation=True)
    summary_ids = model.generate(
        inputs,
        max_length=max_length,
        num_beams=num_beams,
        early_stopping=True
    )
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary

def main():
    # Load pretrained model and tokenizer
    model_name = "t5-small"
    tokenizer = T5Tokenizer.from_pretrained(model_name)
    model = T5ForConditionalGeneration.from_pretrained(model_name)

    # Example text (can replace with dataset or input)
    text = (
        "The quick brown fox jumps over the lazy dog. "
        "This sentence is a pangram, which means it contains every letter of the alphabet at least once."
    )

    summary = summarize(text, model, tokenizer)
    print("Original Text:\n", text)
    print("\nSummary:\n", summary)

if __name__ == "__main__":
    main()